---
title: "Listen Watch and Read: Multimodal Information Authenticity Detection and Source Tracking"
summary: Proposed dataset and model to detect misinformation and AI-generated content in text, video, and audio.
tags:
  - NLP
  - Multimodal DL
date: '2023-07-01T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  focal_point: Smart

links:
url_code: ''
url_pdf: 'https://www.grb.gov.tw/search/planDetail?id=14608604'
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

Our project aims to identify and detect falsified video content using multi-modal information and deep learning. Our team, comprising experts in speech, image, and text analysis, collaborates closely, sharing knowledge to develop innovative machine learning architectures. Additionally, a criminal science expert provides forensic insights, enhancing our efforts to create a robust counterfeit content detection system. We are confident in our ability to develop a sophisticated solution to counteract illegal uses of multimedia generation technologies.

Closely working with the [Taiwan FactCheck Center](https://tfc-taiwan.org.tw/). Proposed an interactive game-based claim labeling system and collected claim detection dataset. Developed an claim verification system that can detect fake news and misinformation.